import streamlit as st
import feedparser
import pandas as pd
import datetime
import os
import urllib.parse

# --- åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ ---
def is_tob_news(title, summary):
    text = (title + summary).lower()
    biz_keywords = ["fc", "ãƒ•ãƒ©ãƒ³ãƒãƒ£ã‚¤ã‚º", "åŠ ç›Ÿåº—", "å¸", "æ¥­å‹™ç”¨", "æ³•äººå‘ã‘", "oem", "dx", "saas", "åº—èˆ—é–‹ç™º", "ç¦åˆ©åšç”Ÿ", "ã‚ªãƒ•ã‚£ã‚¹ç”¨"]
    if any(k in text for k in biz_keywords): return True
    consumer_keywords = ["æ–°ç™ºå£²", "æœŸé–“é™å®š", "é£Ÿã¹æ”¾é¡Œ", "å®Ÿé£Ÿãƒ¬ãƒ", "å…¬å¼sns"]
    if any(k in title for k in consumer_keywords): return False
    base_tob = ["ææº", "å°å…¥", "é–‹å§‹", "æ”¯æ´", "ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³", "é–‹ç™º", "èª¿é”", "è¨­ç«‹"]
    return any(k in text for k in base_tob)

# --- éå»åˆ†ã‚‚å«ã‚ã¦å–å¾—ã™ã‚‹é–¢æ•° ---
def fetch_news(target_date_obj=None):
    """
    target_date_objãŒæŒ‡å®šã•ã‚Œã‚Œã°ãã®æ—¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢çµæœã‚’å–å¾—ã€
    æŒ‡å®šãŒãªã‘ã‚Œã°æœ€æ–°ã®RSSã‚’å–å¾—ã€‚
    """
    if target_date_obj:
        # éå»ã®æ—¥ä»˜ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã®URLï¼ˆPR TIMESã®æ¤œç´¢çµæœãƒšãƒ¼ã‚¸ã‚’åˆ©ç”¨ï¼‰
        date_str = target_date_obj.strftime("%Y%m%d")
        encoded_date = urllib.parse.quote(target_date_obj.strftime("%Yå¹´%mæœˆ%dæ—¥"))
        # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§éå»åˆ†ã‚’ç‹™ã†ï¼ˆRSSçµŒç”±ã§ã¯ãªã„ãŸã‚ç°¡æ˜“çš„ãªã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
        # â€»æœ¬æ¥ã¯RSSé™å®šã ãŒã€ã“ã“ã§ã¯æœ€æ–°RSSã‹ã‚‰è©²å½“æ—¥ã®ã‚‚ã®ã‚’æŠ½å‡ºã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’å„ªå…ˆ
        url = "https://prtimes.jp/main/html/searchrlp/ctcd/100/f/rss.xml"
    else:
        url = "https://prtimes.jp/main/html/searchrlp/ctcd/100/f/rss.xml"
    
    feed = feedparser.parse(url)
    new_data = []
    
    for entry in feed.entries:
        # è¨˜äº‹ã®å…¬é–‹æ—¥ã‚’å–å¾—
        pub_date = datetime.datetime(*entry.published_parsed[:6]).date()
        
        # ç‰¹å®šã®æ—¥ä»˜æŒ‡å®šãŒã‚ã‚‹å ´åˆã¯ãã®æ—¥ã®ã¿ã€ãªã‘ã‚Œã°å…¨ä»¶
        if target_date_obj and pub_date != target_date_obj:
            continue
            
        if is_tob_news(entry.title, entry.summary):
            new_data.append([pub_date.strftime("%Y-%m-%d"), entry.title, entry.link])
    
    db_file = "news_database.csv"
    if new_data:
        df_new = pd.DataFrame(new_data, columns=["date", "title", "url"])
        if os.path.exists(db_file):
            df_old = pd.read_csv(db_file)
            df_final = pd.concat([df_old, df_new]).drop_duplicates(subset=["url"])
        else:
            df_final = df_new
        df_final.to_csv(db_file, index=False, encoding="utf_8_sig")
        return len(new_data)
    return 0

# --- ç”»é¢è¡¨ç¤º ---
st.set_page_config(page_title="toBä¼æ¥­ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼", layout="wide")
st.title("ğŸ“… toBä¼æ¥­ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼")

db_file = "news_database.csv"

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šéå»åˆ†å–å¾—
st.sidebar.header("ğŸ“¥ ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—")
get_date = st.sidebar.date_input("å–å¾—ã—ãŸã„éå»ã®æ—¥ä»˜", datetime.date.today())
if st.sidebar.button("ã“ã®æ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’é¡ã£ã¦å–å¾—"):
    count = fetch_news(get_date)
    if count > 0:
        st.sidebar.success(f"{count}ä»¶ã®è¨˜äº‹ã‚’å–å¾—ãƒ»ä¿å­˜ã—ã¾ã—ãŸï¼")
        st.rerun()
    else:
        st.sidebar.warning("RSSã«ãƒ‡ãƒ¼ã‚¿ãŒæ®‹ã£ã¦ã„ãªã„ã‹ã€æ¡ä»¶ã«åˆã†è¨˜äº‹ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# ï¼ˆä»¥ä¸‹ã€å‰å›ã®æ‰‹å‹•è¿½åŠ ã¨ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶™ç¶šï¼‰
st.sidebar.markdown("---")
st.sidebar.subheader("â• æ‰‹å‹•ã§è¿½åŠ ")
manual_date = st.sidebar.date_input("è¿½åŠ æ—¥", datetime.date.today(), key="manual")
manual_title = st.sidebar.text_input("ã‚¿ã‚¤ãƒˆãƒ«")
manual_url = st.sidebar.text_input("URL")
if st.sidebar.button("ä¿å­˜"):
    add_df = pd.DataFrame([[manual_date.strftime("%Y-%m-%d"), manual_title, manual_url]], columns=["date", "title", "url"])
    if os.path.exists(db_file):
        df_old = pd.read_csv(db_file)
        pd.concat([df_old, add_df]).drop_duplicates().to_csv(db_file, index=False, encoding="utf_8_sig")
    else:
        add_df.to_csv(db_file, index=False, encoding="utf_8_sig")
    st.rerun()

# ãƒ¡ã‚¤ãƒ³è¡¨ç¤º
col1, col2 = st.columns([1, 2])
with col1:
    selected_date = st.date_input("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã§è¡¨ç¤º", datetime.date.today(), key="view")
    target_str = selected_date.strftime("%Y-%m-%d")

with col2:
    st.subheader(f"ğŸ” {target_str} ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹")
    if os.path.exists(db_file):
        df = pd.read_csv(db_file)
        display_df = df[df["date"] == target_str]
        if not display_df.empty:
            for _, row in display_df.iterrows():
                st.markdown(f"âœ… [{row['title']}]({row['url']})")
        else:
            st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€Œå–å¾—ã€ãƒœã‚¿ãƒ³ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚")
