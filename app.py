import streamlit as st
import feedparser
import pandas as pd
import datetime
import os

# è¨­å®šï¼štoBå‘ã‘ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
INCLUDE_KEYWORDS = ["æ³•äººå‘ã‘", "BtoB", "SaaS", "DX", "æ¥­å‹™åŠ¹ç‡åŒ–", "ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³", "ææº", "èª¿é”"]
EXCLUDE_KEYWORDS = ["äººäº‹", "ã‚¹ã‚¤ãƒ¼ãƒ„", "ã‚«ãƒ•ã‚§", "ã‚¢ãƒ‘ãƒ¬ãƒ«", "ç™ºå£²è¨˜å¿µ"]

def fetch_news():
    url = "https://prtimes.jp/main/html/searchrlp/ctcd/100/f/rss.xml"
    feed = feedparser.parse(url)
    today = datetime.date.today().strftime("%Y-%m-%d")
    
    data = []
    for entry in feed.entries:
        is_tob = any(k in entry.title + entry.summary for k in INCLUDE_KEYWORDS)
        is_major = any(k in entry.title for k in EXCLUDE_KEYWORDS)
        if is_tob and not is_major:
            data.append([today, entry.title, entry.link])
    
    db_file = "news_database.csv"
    df_new = pd.DataFrame(data, columns=["date", "title", "url"])
    if os.path.exists(db_file):
        df_old = pd.read_csv(db_file)
        df_final = pd.concat([df_old, df_new]).drop_duplicates(subset=["url"])
    else:
        df_final = df_new
    df_final.to_csv(db_file, index=False, encoding="utf_8_sig")

# --- Streamlit è¡¨ç¤ºè¨­å®š ---
st.title("ğŸ¢ toBä¼æ¥­ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§")
if os.path.exists("news_database.csv"):
    df = pd.read_csv("news_database.csv")
    date_list = sorted(df["date"].unique(), reverse=True)
    selected_date = st.sidebar.selectbox("æ—¥ä»˜ã‚’é¸æŠ", date_list)
    st.subheader(f"ğŸ“… {selected_date} ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹")
    for _, row in df[df["date"] == selected_date].iterrows():
        st.markdown(f"ãƒ» [{row['title']}]({row['url']})")
